# ğŸ§  Image Classification using CNN vs MobileNetV2

## ğŸ“Œ Project Overview  
This project compares two deep learning approaches for image classification of products:
- A **Custom Convolutional Neural Network (CNN)** built from scratch  
- A **MobileNetV2-based Transfer Learning** model (ğŸ† Best Performing)

It aims to solve challenges related to **class imbalance**, **small dataset size**, and **overfitting**, using real-world product images from multiple categories.

---

## ğŸ“‚ Project Resources  
ğŸ”¹ **Dataset (Product Images)**: 1,909 images in 5 classes (Not uploaded due to size)  
ğŸ”¹ **Project Code (.ipynb)**: [View Notebook](https://github.com/SunnyRao07/cnn-vs-mobilenet-image-classification/blob/main/image_classification_cnn_vs_mobilenetv2_code.ipynb)  
ğŸ”¹ **Project Report (DOCX File)**: [Download Report](https://github.com/SunnyRao07/cnn-vs-mobilenet-image-classification/blob/main/cnn_vs_mobilenetv2_report.docx)

---

## ğŸ§¾ Dataset Overview  
- **Total Images**: 1,909  
- **Classes**: Product_1 to Product_5  
- **Images per class**:
  - Product_1: 510  
  - Product_2: 14 (âš ï¸ Highly Imbalanced)  
  - Product_3: 400  
  - Product_4: 385  
  - Product_5: 600  
- **Preprocessing**:
  - Resized to 224x224 pixels  
  - Normalized pixel values to [0,1]  
  - Real-time augmentation: rotation, shift, shear, zoom, flip  
  - Class weights for imbalance handling

---

## ğŸ›  Model Architectures

### 1ï¸âƒ£ **Custom CNN**  
- Conv2D (32 â†’ 64 â†’ 128) + MaxPooling  
- Dense(128) + Dropout(0.5)  
- Softmax output layer  
- Optimizer: Adam (lr=1e-3)  
- EarlyStopping and ModelCheckpoint  
- Epochs: 25  

### 2ï¸âƒ£ **MobileNetV2 Transfer Learning** (ğŸ† Best Model)  
- Pretrained on ImageNet (without top layers)  
- Classification head: GAP â†’ Dense(128) â†’ Dropout â†’ Dense(5, softmax)  
- Training Strategy:
  - Phase 1: Freeze base, train head for 10 epochs  
  - Phase 2: Unfreeze last 20 layers, fine-tune for 5 epochs (lr=1e-5)  
- EarlyStopping enabled in both phases  

---

## ğŸ“ˆ Model Performance

| Model         | Accuracy | Test Loss | Remarks                          |
|---------------|----------|-----------|----------------------------------|
| Custom CNN    | 92.68%   | 0.25      | Overfitting observed             |
| **MobileNetV2** | **97.21%** | **0.07**   | Generalized well, faster training |

ğŸ“Œ **Note**: Both models failed to correctly classify `Product_2` due to very limited training data.

---

## ğŸ“Š Evaluation Metrics  
- **Accuracy**  
- **Loss**  
- **Precision, Recall, F1-Score (per class)**  
- **Confusion Matrix**  
- **Training & Validation Curves**

---

## ğŸ§  Key Observations  
- Transfer learning significantly improved accuracy and generalization  
- CNN showed signs of overfitting and required more memory  
- Severe class imbalance led to 0% F1 for Product_2 in both models  
- MobileNetV2 had ~165K trainable parameters vs CNNâ€™s ~11M  

---

## ğŸš€ Future Scope  
ğŸ”¹ Apply **advanced synthetic augmentation** (e.g., GANs) for minority classes  
ğŸ”¹ Explore **EfficientNet** or **ResNet50** for better transfer performance  
ğŸ”¹ Consider **active learning** for iterative data improvement  
ğŸ”¹ Deploy the model via Flask or Streamlit for real-time classification

---

## ğŸ— Project Highlights  
This project demonstrates a complete **deep learning pipeline** including:  
âœ”ï¸ Data Preprocessing & Augmentation  
âœ”ï¸ CNN & Transfer Learning Model Development  
âœ”ï¸ Evaluation with Visualization  
âœ”ï¸ Addressing Class Imbalance using Weights  
âœ”ï¸ Academic Report & Documentation

---

## ğŸ‘¥ Authors  
- Sunny Rao Karegam  
- Sandeep Kumar Kandagatla  
- Srikanth Kannamoni  
- Alphin Stivi John  

ğŸ“ MSc Data Analytics â€“ Dublin Business School (2025)

---

## ğŸ“Œ Note  
This is an academic project submitted as part of the **Machine Learning & Pattern Recognition** module.  
The dataset is not included in this repository due to space/privacy restrictions.  
Please contact the authors for access or use a similar open-source dataset for replication.

---
